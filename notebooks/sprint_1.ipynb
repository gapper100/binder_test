{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "The goal for this sprint is for your team to get to know the data.\n",
    "\n",
    "Some questions you may want to ask:\n",
    "- How are the prices distributed?\n",
    "- How many missing values are there?\n",
    "- What features may be interesting, intuitively?\n",
    "- Can we construct new features based on the existing ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set() # For aesthetic purposes\n",
    "pd.set_option(\"display.max_columns\", 101) # So we can see all columns of our DataFrame\n",
    "pd.set_option('display.max_rows', 100) # So we can more rows of our DataFrame\n",
    "np.random.seed(42) # So all our results will be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to analyse our data, we first have to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "df_train = pd.read_csv(\"../data/train.csv\").set_index('Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset also comes with a handy little file called `data_description.txt`, which explains exactly what each column means. How convenient! This is often surprisingly difficult in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data/data_description.txt', 'r+') as f:\n",
    "    x = f.read()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' `.head()` function allows us to take a look at the first few rows, so we can get a sense of what the data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.describe()` function shows descriptive statistics for all numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have spotted it above, but some columns have values that show up as `NaN` (Not a Number). This can indicate that a field is simply not applicable (if you don't have a pool... what's \"the quality of your pool\"?), or it can indicate that we're just missing some data (we don't know when this house was built!). Let's have a look at how many data points are missing for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data\n",
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the looks of it, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now let's get visual. What does the distribution of our target variable, `SalePrice` look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram\n",
    "sns.distplot(df_train['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, cool. And how does it correlate to some of our variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatter plot GrLivArea/SalePrice\n",
    "var = 'GrLivArea'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! These two variables are clearly very strongly correlated. This is good to keep in mind for the next sprint, when we'll build our first model!\n",
    "\n",
    "**Experiment with this, and have a look at different variables!**\n",
    "\n",
    "_Tip: you can use the .columns attribute of our dataframe (so df_train.columns) to find out the names of all columns._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical variables, a scatter plot may not be the right solution. But seaborn makes it easy to create other plots as well. For instance, the code below draws these box plots for every category in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Box plot overallqual/saleprice\n",
    "var = 'OverallQual'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yes, the price is obviously dependent on the 'Overall quality' of the house! Who would have guessed.\n",
    "\n",
    "**Experiment with this, and have a look at different variables!**\n",
    "\n",
    "_Tip: you can use the .dtypes attribute of our dataframe (so df_train.dtypes) to find out the data types of all our columns. `float64` and `int64` columns are numerical, `object` columns are (usually) categorical!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, going through all these features individually can be a bit tedious... but again, Seaborn is here to help us! The outstanding plot below (a `heatmap` plot over the `corr`elations of our DataFrame. Shows us the correlations between each of our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corrmat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't that beautiful?\n",
    "\n",
    "What do you see here? Anything peculiar that stands out? Can you explain it?\n",
    "\n",
    "For instance, we see two little squares. That's usually something to be wary of, as it may indicate multicollinearity. In this case, that actually makes sense! Of course the area of a garage is very strongly correlated to the number of cars that can fit in it, and it makes sense that the area of the basement would be about the same as the area of the first floor. In fact, perhaps some people who made this data set even considered the basement the first floor. Something to be aware of, in the very least, and it's probably smart to discard one of these.\n",
    "\n",
    "Furthermore, we see that the bottom row (or rightmost column) contains our target variable, the SalePrice. Bright cells in this one are the ones to keep in mind for later when we start building our models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that we have a feel for which variables may be important, let's have a closer look at the best ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SalePrice correlation matrix\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(df_train[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! So we still see those two squares of possible multicollinearity, so we have to take them into account. Other than that, this gives us a good idea of which features we may want to use for our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how these most interesting features all correlate to one another. One way to do this is by using `seaborn`'s amazing `pairplot` function, which allows you to create scatter plots and histograms of many features in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#scatterplot\n",
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(df_train[cols], size = 2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems all features have a positive correlation with SalePrice... perhaps bigger is better (or at least more expensive) when it comes to houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the code for a number of the plots in this Notebook were copied from [this](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python) amazing Kaggle submission üôè"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vesting] *",
   "language": "python",
   "name": "conda-env-vesting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
